{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIPlWwEXA1Lf",
    "outputId": "6a765722-b230-4249-a39a-71784263c0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== CYCLE 0 ==========\n",
      "write at 12 for core 1\n",
      "[L1 cache write for 12 on core 1]\n",
      "[Cycle 0] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 1 ==========\n",
      "read at 16 for core 0\n",
      "[L1 cache miss for 16 on core 0]\n",
      "[L2 cache miss for 16 on core 0]\n",
      "[L3 cache miss for 16 on core 0]\n",
      "[Cycle 1] ➜ New CPU request queued: Core 0, READ Addr 16\n",
      "[Cycle 1] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 2 ==========\n",
      "read at 15 for core 0\n",
      "[L1 cache miss for 15 on core 0]\n",
      "[L2 cache miss for 15 on core 0]\n",
      "[L3 cache miss for 15 on core 0]\n",
      "[Cycle 2] ➜ New CPU request queued: Core 0, READ Addr 15\n",
      "[Cycle 2] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 3 ==========\n",
      "write at 16 for core 0\n",
      "[L1 cache write for 16 on core 0]\n",
      "[Cycle 3] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 4 ==========\n",
      "read at 19 for core 1\n",
      "[L1 cache miss for 19 on core 1]\n",
      "[L2 cache miss for 19 on core 1]\n",
      "[L3 cache miss for 19 on core 1]\n",
      "[Cycle 4] ➜ New CPU request queued: Core 1, READ Addr 19\n",
      "[Cycle 4] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 5 ==========\n",
      "write at 19 for core 1\n",
      "[L1 cache write for 19 on core 1]\n",
      "[Cycle 5] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 6 ==========\n",
      "read at 2 for core 1\n",
      "[L1 cache miss for 2 on core 1]\n",
      "[L2 cache miss for 2 on core 1]\n",
      "[L3 cache miss for 2 on core 1]\n",
      "[Cycle 6] ➜ New CPU request queued: Core 1, READ Addr 2\n",
      "[Cycle 6] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 7 ==========\n",
      "write at 17 for core 0\n",
      "[L1 cache write for 17 on core 0]\n",
      "[Cycle 7] ➜ New DDR request queued: Core 0, READ Addr 16\n",
      "[Cycle 7] ➜ New DDR request queued: Core 0, READ Addr 15\n",
      "[Cycle 7] ➜ Scheduling READ for Addr 16 (Core 0)\n",
      "                  ↳ Bank 0, Row 1 | ROW MISS | Will complete at Cycle 67\n",
      "\n",
      "========== CYCLE 8 ==========\n",
      "read at 20 for core 1\n",
      "[L1 cache miss for 20 on core 1]\n",
      "[L2 cache miss for 20 on core 1]\n",
      "[L3 cache miss for 20 on core 1]\n",
      "[Cycle 8] ➜ New CPU request queued: Core 1, READ Addr 20\n",
      "[Cycle 8] ➜ Scheduling READ for Addr 15 (Core 0)\n",
      "                  ↳ Bank 3, Row 0 | ROW MISS | Will complete at Cycle 68\n",
      "\n",
      "========== CYCLE 9 ==========\n",
      "write at 14 for core 1\n",
      "[L1 cache write for 14 on core 1]\n",
      "[Cycle 9] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 10 ==========\n",
      "write at 17 for core 1\n",
      "[L1 cache write for 17 on core 1]\n",
      "[Cycle 10] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 11 ==========\n",
      "read at 12 for core 1\n",
      "[L1 cache hit for 12 on core 1]\n",
      "[Cycle 11] ➜ New DDR request queued: Core 1, READ Addr 19\n",
      "\n",
      "========== CYCLE 12 ==========\n",
      "write at 20 for core 0\n",
      "[L1 cache write for 20 on core 0]\n",
      "[Cycle 12] ➜ New DDR request queued: Core 1, READ Addr 2\n",
      "[Cycle 12] ➜ Scheduling READ for Addr 2 (Core 1)\n",
      "                  ↳ Bank 2, Row 0 | ROW MISS | Will complete at Cycle 72\n",
      "\n",
      "========== CYCLE 13 ==========\n",
      "write at 10 for core 0\n",
      "[L1 cache write for 10 on core 0]\n",
      "\n",
      "========== CYCLE 14 ==========\n",
      "read at 2 for core 0\n",
      "[L1 cache miss for 2 on core 0]\n",
      "[L2 cache miss for 2 on core 0]\n",
      "[L3 cache miss for 2 on core 0]\n",
      "[Cycle 14] ➜ New CPU request queued: Core 0, READ Addr 2\n",
      "[Cycle 14] ➜ New DDR request queued: Core 1, READ Addr 20\n",
      "\n",
      "========== CYCLE 15 ==========\n",
      "write at 4 for core 1\n",
      "[L1 cache write for 4 on core 1]\n",
      "\n",
      "========== CYCLE 16 ==========\n",
      "read at 10 for core 1\n",
      "[L1 cache miss for 10 on core 1]\n",
      "[L2 cache miss for 10 on core 1]\n",
      "[L3 cache miss for 10 on core 1]\n",
      "[Cycle 16] ➜ New CPU request queued: Core 1, READ Addr 10\n",
      "\n",
      "========== CYCLE 17 ==========\n",
      "write at 3 for core 0\n",
      "[L1 cache write for 3 on core 0]\n",
      "[Cycle 17] ➜ Scheduling READ for Addr 20 (Core 1)\n",
      "                  ↳ Bank 0, Row 1 | ROW HIT | Will complete at Cycle 37\n",
      "\n",
      "========== CYCLE 18 ==========\n",
      "read at 17 for core 0\n",
      "[L1 cache hit for 17 on core 0]\n",
      "[Cycle 18] ➜ Scheduling READ for Addr 19 (Core 1)\n",
      "                  ↳ Bank 3, Row 1 | ROW MISS | Will complete at Cycle 78\n",
      "\n",
      "========== CYCLE 19 ==========\n",
      "read at 6 for core 1\n",
      "[L1 cache hit for 6 on core 1]\n",
      "[Cycle 19] ➜ New DDR request queued: Core 0, READ Addr 2\n",
      "\n",
      "========== CYCLE 20 ==========\n",
      "write at 18 for core 0\n",
      "[L1 cache write for 18 on core 0]\n",
      "\n",
      "========== CYCLE 21 ==========\n",
      "write at 12 for core 0\n",
      "[L1 cache write for 12 on core 0]\n",
      "\n",
      "========== CYCLE 22 ==========\n",
      "write at 6 for core 1\n",
      "[L1 cache write for 6 on core 1]\n",
      "[Cycle 22] ➜ New DDR request queued: Core 1, READ Addr 10\n",
      "[Cycle 22] ➜ Scheduling READ for Addr 10 (Core 1)\n",
      "                  ↳ Bank 2, Row 0 | ROW HIT | Will complete at Cycle 42\n",
      "\n",
      "========== CYCLE 23 ==========\n",
      "write at 8 for core 0\n",
      "[L1 cache write for 8 on core 0]\n",
      "\n",
      "========== CYCLE 24 ==========\n",
      "read at 4 for core 1\n",
      "[L1 cache hit for 4 on core 1]\n",
      "\n",
      "========== CYCLE 25 ==========\n",
      "read at 2 for core 1\n",
      "[L1 cache miss for 2 on core 1]\n",
      "[L2 cache miss for 2 on core 1]\n",
      "[L3 cache miss for 2 on core 1]\n",
      "[Cycle 25] ➜ New CPU request queued: Core 1, READ Addr 2\n",
      "\n",
      "========== CYCLE 26 ==========\n",
      "read at 12 for core 1\n",
      "[L1 cache hit for 12 on core 1]\n",
      "\n",
      "========== CYCLE 27 ==========\n",
      "read at 16 for core 1\n",
      "[L1 cache hit for 16 on core 1]\n",
      "\n",
      "========== CYCLE 28 ==========\n",
      "write at 18 for core 1\n",
      "[L1 cache write for 18 on core 1]\n",
      "\n",
      "========== CYCLE 29 ==========\n",
      "read at 14 for core 0\n",
      "[L1 cache hit for 14 on core 0]\n",
      "\n",
      "========== CYCLE 30 ==========\n",
      "read at 11 for core 0\n",
      "[L1 cache hit for 11 on core 0]\n",
      "\n",
      "========== CYCLE 31 ==========\n",
      "write at 15 for core 1\n",
      "[L1 cache write for 15 on core 1]\n",
      "\n",
      "========== CYCLE 32 ==========\n",
      "write at 7 for core 0\n",
      "[L1 cache write for 7 on core 0]\n",
      "[Cycle 32] ➜ New DDR request queued: Core 1, READ Addr 2\n",
      "\n",
      "========== CYCLE 33 ==========\n",
      "write at 7 for core 0\n",
      "[L1 cache write for 7 on core 0]\n",
      "\n",
      "========== CYCLE 34 ==========\n",
      "write at 1 for core 0\n",
      "[L1 cache write for 1 on core 0]\n",
      "\n",
      "========== CYCLE 35 ==========\n",
      "read at 7 for core 0\n",
      "[L1 cache hit for 7 on core 0]\n",
      "\n",
      "========== CYCLE 36 ==========\n",
      "write at 17 for core 1\n",
      "[L1 cache write for 17 on core 1]\n",
      "\n",
      "========== CYCLE 37 ==========\n",
      "read at 20 for core 0\n",
      "[L1 cache hit for 20 on core 0]\n",
      "[Cycle 37] ✔ READ COMPLETE (Core 1, Addr 20) => 0\n",
      "[L2 cache write for 4 on core 1]\n",
      "\n",
      "========== CYCLE 38 ==========\n",
      "write at 3 for core 0\n",
      "[L1 cache write for 3 on core 0]\n",
      "\n",
      "========== CYCLE 39 ==========\n",
      "write at 1 for core 1\n",
      "[L1 cache write for 1 on core 1]\n",
      "\n",
      "========== CYCLE 40 ==========\n",
      "write at 5 for core 1\n",
      "[L1 cache write for 5 on core 1]\n",
      "\n",
      "========== CYCLE 41 ==========\n",
      "write at 1 for core 1\n",
      "[L1 cache write for 1 on core 1]\n",
      "\n",
      "========== CYCLE 42 ==========\n",
      "write at 19 for core 0\n",
      "[L1 cache write for 19 on core 0]\n",
      "[Cycle 42] ✔ READ COMPLETE (Core 1, Addr 10) => 0\n",
      "\n",
      "========== CYCLE 43 ==========\n",
      "write at 2 for core 1\n",
      "[L1 cache write for 2 on core 1]\n",
      "\n",
      "========== CYCLE 44 ==========\n",
      "write at 1 for core 1\n",
      "[L1 cache write for 1 on core 1]\n",
      "\n",
      "========== CYCLE 45 ==========\n",
      "write at 12 for core 0\n",
      "[L1 cache write for 12 on core 0]\n",
      "\n",
      "========== CYCLE 46 ==========\n",
      "read at 15 for core 1\n",
      "[L1 cache hit for 15 on core 1]\n",
      "\n",
      "========== CYCLE 47 ==========\n",
      "write at 5 for core 1\n",
      "[L1 cache write for 5 on core 1]\n",
      "\n",
      "========== CYCLE 48 ==========\n",
      "write at 1 for core 1\n",
      "[L1 cache write for 1 on core 1]\n",
      "\n",
      "========== CYCLE 49 ==========\n",
      "write at 10 for core 1\n",
      "[L1 cache write for 10 on core 1]\n",
      "\n",
      "========== CYCLE 50 ==========\n",
      "write at 14 for core 1\n",
      "[L1 cache write for 14 on core 1]\n",
      "\n",
      "========== CYCLE 51 ==========\n",
      "read at 13 for core 1\n",
      "[L1 cache hit for 13 on core 1]\n",
      "\n",
      "========== CYCLE 52 ==========\n",
      "write at 9 for core 1\n",
      "[L1 cache write for 9 on core 1]\n",
      "\n",
      "========== CYCLE 53 ==========\n",
      "read at 8 for core 0\n",
      "[L1 cache hit for 8 on core 0]\n",
      "\n",
      "========== CYCLE 54 ==========\n",
      "write at 14 for core 1\n",
      "[L1 cache write for 14 on core 1]\n",
      "\n",
      "========== CYCLE 55 ==========\n",
      "write at 17 for core 0\n",
      "[L1 cache write for 17 on core 0]\n",
      "\n",
      "========== CYCLE 56 ==========\n",
      "write at 15 for core 0\n",
      "[L1 cache write for 15 on core 0]\n",
      "\n",
      "========== CYCLE 57 ==========\n",
      "read at 18 for core 1\n",
      "[L1 cache hit for 18 on core 1]\n",
      "\n",
      "========== CYCLE 58 ==========\n",
      "write at 19 for core 0\n",
      "[L1 cache write for 19 on core 0]\n",
      "\n",
      "========== CYCLE 59 ==========\n",
      "write at 13 for core 1\n",
      "[L1 cache write for 13 on core 1]\n",
      "\n",
      "========== CYCLE 60 ==========\n",
      "write at 6 for core 1\n",
      "[L1 cache write for 6 on core 1]\n",
      "\n",
      "========== CYCLE 61 ==========\n",
      "read at 20 for core 0\n",
      "[L1 cache hit for 20 on core 0]\n",
      "\n",
      "========== CYCLE 62 ==========\n",
      "write at 18 for core 1\n",
      "[L1 cache write for 18 on core 1]\n",
      "\n",
      "========== CYCLE 63 ==========\n",
      "read at 18 for core 0\n",
      "[L1 cache hit for 18 on core 0]\n",
      "\n",
      "========== CYCLE 64 ==========\n",
      "write at 1 for core 0\n",
      "[L1 cache write for 1 on core 0]\n",
      "\n",
      "========== CYCLE 65 ==========\n",
      "read at 5 for core 0\n",
      "[L1 cache hit for 5 on core 0]\n",
      "\n",
      "========== CYCLE 66 ==========\n",
      "write at 17 for core 1\n",
      "[L1 cache write for 17 on core 1]\n",
      "\n",
      "========== CYCLE 67 ==========\n",
      "read at 15 for core 0\n",
      "[L1 cache hit for 15 on core 0]\n",
      "[Cycle 67] ✔ READ COMPLETE (Core 0, Addr 16) => 0\n",
      "[L2 cache write for 16 on core 0]\n",
      "\n",
      "========== CYCLE 68 ==========\n",
      "read at 1 for core 1\n",
      "[L1 cache hit for 1 on core 1]\n",
      "[Cycle 68] ✔ READ COMPLETE (Core 0, Addr 15) => 0\n",
      "[L2 cache write for 12 on core 0]\n",
      "\n",
      "========== CYCLE 69 ==========\n",
      "read at 13 for core 0\n",
      "[L1 cache hit for 13 on core 0]\n",
      "\n",
      "========== CYCLE 70 ==========\n",
      "read at 20 for core 1\n",
      "[L1 cache hit for 20 on core 1]\n",
      "\n",
      "========== CYCLE 71 ==========\n",
      "write at 4 for core 1\n",
      "[L1 cache write for 4 on core 1]\n",
      "\n",
      "========== CYCLE 72 ==========\n",
      "write at 13 for core 0\n",
      "[L1 cache write for 13 on core 0]\n",
      "[Cycle 72] ✔ READ COMPLETE (Core 1, Addr 2) => 0\n",
      "[L2 cache write for 0 on core 1]\n",
      "\n",
      "========== CYCLE 73 ==========\n",
      "read at 0 for core 1\n",
      "[L1 cache hit for 0 on core 1]\n",
      "[Cycle 73] ➜ Scheduling READ for Addr 2 (Core 0)\n",
      "                  ↳ Bank 2, Row 0 | ROW HIT | Will complete at Cycle 93\n",
      "\n",
      "========== CYCLE 74 ==========\n",
      "write at 19 for core 0\n",
      "[L1 cache write for 19 on core 0]\n",
      "\n",
      "========== CYCLE 75 ==========\n",
      "write at 6 for core 1\n",
      "[L1 cache write for 6 on core 1]\n",
      "\n",
      "========== CYCLE 76 ==========\n",
      "read at 3 for core 0\n",
      "[L1 cache hit for 3 on core 0]\n",
      "\n",
      "========== CYCLE 77 ==========\n",
      "write at 20 for core 0\n",
      "[L1 cache write for 20 on core 0]\n",
      "\n",
      "========== CYCLE 78 ==========\n",
      "write at 3 for core 1\n",
      "[L1 cache write for 3 on core 1]\n",
      "[Cycle 78] ✔ READ COMPLETE (Core 1, Addr 19) => 0\n",
      "[L2 cache write for 16 on core 1]\n",
      "\n",
      "========== CYCLE 79 ==========\n",
      "write at 20 for core 1\n",
      "[L1 cache write for 20 on core 1]\n",
      "\n",
      "========== CYCLE 80 ==========\n",
      "write at 8 for core 1\n",
      "[L1 cache write for 8 on core 1]\n",
      "\n",
      "========== CYCLE 81 ==========\n",
      "read at 8 for core 1\n",
      "[L1 cache hit for 8 on core 1]\n",
      "\n",
      "========== CYCLE 82 ==========\n",
      "write at 18 for core 1\n",
      "[L1 cache write for 18 on core 1]\n",
      "\n",
      "========== CYCLE 83 ==========\n",
      "read at 19 for core 1\n",
      "[L1 cache hit for 19 on core 1]\n",
      "\n",
      "========== CYCLE 84 ==========\n",
      "write at 14 for core 1\n",
      "[L1 cache write for 14 on core 1]\n",
      "\n",
      "========== CYCLE 85 ==========\n",
      "read at 5 for core 0\n",
      "[L1 cache hit for 5 on core 0]\n",
      "\n",
      "========== CYCLE 86 ==========\n",
      "write at 0 for core 0\n",
      "[L1 cache write for 0 on core 0]\n",
      "\n",
      "========== CYCLE 87 ==========\n",
      "write at 11 for core 1\n",
      "[L1 cache write for 11 on core 1]\n",
      "\n",
      "========== CYCLE 88 ==========\n",
      "write at 1 for core 0\n",
      "[L1 cache write for 1 on core 0]\n",
      "\n",
      "========== CYCLE 89 ==========\n",
      "read at 9 for core 0\n",
      "[L1 cache hit for 9 on core 0]\n",
      "\n",
      "========== CYCLE 90 ==========\n",
      "write at 4 for core 0\n",
      "[L1 cache write for 4 on core 0]\n",
      "\n",
      "========== CYCLE 91 ==========\n",
      "read at 1 for core 0\n",
      "[L1 cache hit for 1 on core 0]\n",
      "\n",
      "========== CYCLE 92 ==========\n",
      "read at 2 for core 0\n",
      "[L1 cache hit for 2 on core 0]\n",
      "\n",
      "========== CYCLE 93 ==========\n",
      "write at 9 for core 0\n",
      "[L1 cache write for 9 on core 0]\n",
      "[Cycle 93] ✔ READ COMPLETE (Core 0, Addr 2) => 0\n",
      "[L2 cache write for 0 on core 0]\n",
      "\n",
      "========== CYCLE 94 ==========\n",
      "read at 15 for core 0\n",
      "[L1 cache hit for 15 on core 0]\n",
      "[Cycle 94] ➜ Scheduling READ for Addr 2 (Core 1)\n",
      "                  ↳ Bank 2, Row 0 | ROW HIT | Will complete at Cycle 114\n",
      "\n",
      "========== CYCLE 95 ==========\n",
      "write at 10 for core 0\n",
      "[L1 cache write for 10 on core 0]\n",
      "[Cycle 95] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 96 ==========\n",
      "write at 13 for core 0\n",
      "[L1 cache write for 13 on core 0]\n",
      "[Cycle 96] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 97 ==========\n",
      "read at 4 for core 1\n",
      "[L1 cache hit for 4 on core 1]\n",
      "[Cycle 97] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 98 ==========\n",
      "read at 12 for core 1\n",
      "[L1 cache hit for 12 on core 1]\n",
      "[Cycle 98] No pending DDR requests to schedule.\n",
      "\n",
      "========== CYCLE 99 ==========\n",
      "write at 2 for core 0\n",
      "[L1 cache write for 2 on core 0]\n",
      "[Cycle 99] No pending DDR requests to schedule.\n",
      "{'core': 0, 'L1': {'level': 'L1', 'hits': 17, 'misses': 3, 'hit_rate': 0.85}, 'L2': {'level': 'L2', 'hits': 0, 'misses': 3, 'hit_rate': 0.0}, 'L3': {'level': 'L3', 'hits': 0, 'misses': 3, 'hit_rate': 0.0}}\n",
      "{'core': 1, 'L1': {'level': 'L1', 'hits': 15, 'misses': 5, 'hit_rate': 0.75}, 'L2': {'level': 'L2', 'hits': 0, 'misses': 5, 'hit_rate': 0.0}, 'L3': {'level': 'L3', 'hits': 0, 'misses': 5, 'hit_rate': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# This code has generated by ChatGPT for the most part\n",
    "# It has then been reviewed, corrected, commented and augmented by\n",
    "# a humabn being (Eric).\n",
    "\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "# This model represents a memory hierarchy with\n",
    "# - 3 levels of cache (L1, L2, L3)\n",
    "# - a DDR memory implemening some simple optimization features (see the DDR class)\n",
    "# - an interconnect\n",
    "# The number of cores, levels of cache, characteristics of the cache (number of ways,...)\n",
    "# are parameters and can be modified.\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# CacheLine: Represents a single cache line in the cache hierarchy\n",
    "# -----------------------------------------------------\n",
    "# We are using n-way associative cache:\n",
    "# - Each set contains n cache lines with a tag entry.\n",
    "# - Each line contains m bytes.\n",
    "#\n",
    "# A memory Address is structured as follows:\n",
    "# +----------------+-----------+-----------+\n",
    "# |     Tag        |   Index   |  Offset   |\n",
    "# +----------------+-----------+-----------+\n",
    "# where\n",
    "#\n",
    "# (Used to find blk) (Set selection) (Byte in block)\n",
    "# \"Block\" and \"line\" are used interchangeably.\n",
    "# Cache Structure:\n",
    "# Set 0: [Block 0] [Block 1] [Block 2] [Block 3]  ← 4-way associativity (n=4)\n",
    "# Set 1: [Block 0] [Block 1] [Block 2] [Block 3]\n",
    "# ...\n",
    "# Set N: [Block 0] [Block 1] [Block 2] [Block 3]\n",
    "\n",
    "class CacheLine:\n",
    "    def __init__(self):\n",
    "        self.valid = False       # Indicates if this line holds valid data\n",
    "        self.tag = None          # Tag of the data block\n",
    "        self.data = 0            # Simulated data content\n",
    "        self.dirty = False       # Indicates if the line has been written to (for write-back)\n",
    "\n",
    "# Implements Pseudo-LRU (PLRU) replacement policy for N-way set associative caches\n",
    "# The pseudoi-LRU is used to determine the bock to replace in case of cache miss.\n",
    "# A binary tree is used to implement the PLRU algorithm. There is one tree per set.\n",
    "# For a 4-way cache, 3 bits are used to determine the block to select.\n",
    "#\n",
    "#      Bit 0 (Root)\n",
    "#     /           \\\n",
    "#   Bit 1         Bit 2\n",
    "#   /   \\         /   \\\n",
    "# Block0 Block1 Block2 Block3\n",
    "#\n",
    "# Each node of the tree contains a direction (left=0, right=1) that indicates\n",
    "# the path to follow to find the next pLRU entry.\n",
    "class PLRU:\n",
    "    def __init__(self, ways):\n",
    "        self.bits = [0] * (ways - 1)  # Tree structure to track usage\n",
    "        self.ways = ways\n",
    "\n",
    "    # Update the binary tree in case of a hit\n",
    "    # The bits in the tree are modified to point \"away\" from this entry\n",
    "    # (which is the MRU)\n",
    "    def update_on_access(self, way):\n",
    "        idx = 0\n",
    "        num_levels = self.ways.bit_length() - 1\n",
    "        for level in range(num_levels):\n",
    "            # Select direction according to the way\n",
    "             # (e.g., way=3=0b101 in a 4-way cache => direction = 1 (right subtree), 0 (left subtree)\n",
    "            direction = (way >> (num_levels - 1 - level)) & 1\n",
    "            self.bits[idx] = 1-direction # Point to the opposite direction\n",
    "            idx = (idx << 1)+ 1 + direction\n",
    "\n",
    "    # Compute the next victim (the pLRU)\n",
    "    # The block is selected by traversing the tree according\n",
    "    # to the directions given by each bit.\n",
    "    def get_victim(self):\n",
    "        idx = 0\n",
    "        way = 0\n",
    "        for level in range(self.ways.bit_length() - 1):\n",
    "            direction = self.bits[idx]\n",
    "            way = (way << 1) | direction\n",
    "            idx = ( idx << 1) + 1 + direction\n",
    "        return way\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Represents a memory access request (either read or write)\n",
    "# ---------------------------------------------------------\n",
    "class DDRRequest:\n",
    "    def __init__(self, core_id, time, req_type, addr, callback=None, value=None):\n",
    "        self.core_id = core_id\n",
    "        self.time = time              # Time of request\n",
    "        self.req_type = req_type      # 'read' or 'write'\n",
    "        self.addr = addr\n",
    "        self.callback = callback      # Callback function to return read result\n",
    "        self.value = value            # Value to write (for write requests)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.time < other.time\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Interconnect model between CPU cores and DDR, with bandwidth and latency\n",
    "# ---------------------------------------------------------\n",
    "# Behaviour :\n",
    "# - Each request takes at least some base delay to be served.\n",
    "# - A request may be delayed if the interconnect bandwidh has been \"used\"\n",
    "# The interconnect canot serve more than \"bandwidth\" request in one cycle.\n",
    "# Note\n",
    "# - Using a heapqueue ensures that all items are and remain sorted\n",
    "#   according to their ready_time (and req)\n",
    "#\n",
    "\n",
    "\n",
    "class Interconnect:\n",
    "    def __init__(self, memory, delay=5, bandwidth=4):\n",
    "        self.memory = memory\n",
    "        self.queue = []               # Queue of pending memory requests\n",
    "        self.delay = delay            # Base delay before forwarding to DDR\n",
    "        self.bandwidth = bandwidth    # Max number of requests per cycle\n",
    "        self.cycle = 0\n",
    "\n",
    "    # Push a request in the request queue.\n",
    "    # We push the couple (ready_time, request) where ready_time is the earliest\n",
    "    # time at which the request may be served.\n",
    "    def request(self, req):\n",
    "        print(f\"[Cycle {self.cycle}] ➜ New CPU request queued: Core {req.core_id}, {req.req_type.upper()} Addr {req.addr}\")\n",
    "        ready_time = self.cycle + self.delay + random.randint(0, 2)\n",
    "        heapq.heappush(self.queue, (ready_time, req))\n",
    "\n",
    "    # Process the interconnect current cycle\n",
    "    def tick(self):\n",
    "        processed = 0\n",
    "        temp_queue = []\n",
    "\n",
    "        # Forward requests to DDR respecting bandwidth limit\n",
    "        while self.queue and self.queue[0][0] <= self.cycle and processed < self.bandwidth:\n",
    "            _, req = heapq.heappop(self.queue)\n",
    "            self.memory.request(req)\n",
    "            processed += 1\n",
    "\n",
    "        #[TODO]: the following code seems useless since the queue is always\n",
    "        #sorted...\n",
    "\n",
    "        # Defer excess requests for next cycles\n",
    "        while self.queue and self.queue[0][0] <= self.cycle:\n",
    "            temp_queue.append(heapq.heappop(self.queue))\n",
    "        for item in temp_queue:\n",
    "            heapq.heappush(self.queue, item)\n",
    "\n",
    "        self.cycle += 1\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#  DDR memory model with banks, row buffers, and latency variations\n",
    "# Access latencies depend on the active bank\n",
    "# Each bank has a row buffer. An access to the same row is faster. In case of\n",
    "# miss, an access precharge and activate delay is added.\n",
    "#\n",
    "# The parameters are\n",
    "# tRCD (Row to Column Delay)\n",
    "# tRP (Row Precharge) : time to close one row of memory cell before opening another row\n",
    "#                       in the same bank.\n",
    "# tCAS (Column Access Strobe latency)\n",
    "# tRC (Row Cycle time)\n",
    "# Behaviour:\n",
    "# - The DDR requests coming from the two cores are queued and arbitrated per cycle by the DDR controler.\n",
    "# - The requests are re-ordered so that the best next-command is served first:\n",
    "#   - prefer row hits\n",
    "#   - avoid accesses to busy banks\n",
    "# - The bank is determined by the address' LSB: row = addr % num_banks\n",
    "# - Each row contains 16 addresses: row = addr // 16\n",
    "# ---------------------------------------------------------\n",
    "class DDRMemory:\n",
    "    def __init__(self, latency=50, row_hit_latency=20, row_miss_penalty=30, precharge_time=10, num_banks=4):\n",
    "        self.base_latency = latency\n",
    "        self.row_hit_latency = row_hit_latency\n",
    "        self.row_miss_penalty = row_miss_penalty\n",
    "        self.precharge_time = precharge_time\n",
    "        self.num_banks = num_banks\n",
    "        self.bank_row_buffers = [None for _ in range(num_banks)]\n",
    "        self.bank_precharge_end = [0 for _ in range(num_banks)]\n",
    "        self.memory = {}\n",
    "        self.cycle = 0\n",
    "\n",
    "        self.pending = []  # Requests waiting to be scheduled\n",
    "        self.scheduled = []  # Requests that have been scheduled for completion\n",
    "        self.last_address_time = {}  # Track the latest cycle each address is scheduled to enforce order\n",
    "\n",
    "    def _get_bank(self, addr):\n",
    "        return addr % self.num_banks\n",
    "\n",
    "    def _get_row(self, addr):\n",
    "        return addr // 16  # Example: each row covers 16 addresses\n",
    "\n",
    "    # Queue a request\n",
    "    def request(self, req):\n",
    "        print(f\"[Cycle {self.cycle}] ➜ New DDR request queued: Core {req.core_id}, {req.req_type.upper()} Addr {req.addr}\")\n",
    "        self.pending.append((self.cycle, req))\n",
    "\n",
    "    # Process the DDR current cycle\n",
    "    def tick(self):\n",
    "        self._issue_best_request()\n",
    "\n",
    "        while self.scheduled and self.scheduled[0][0] <= self.cycle:\n",
    "            _, req = heapq.heappop(self.scheduled)\n",
    "            if req.req_type == 'read':\n",
    "                val = self.memory.get(req.addr, 0)\n",
    "                print(f\"[Cycle {self.cycle}] ✔ READ COMPLETE (Core {req.core_id}, Addr {req.addr}) => {val}\")\n",
    "                if req.callback:\n",
    "                    req.callback(val)\n",
    "            elif req.req_type == 'write':\n",
    "                self.memory[req.addr] = req.value\n",
    "                print(f\"[Cycle {self.cycle}] ✔ WRITE COMPLETE (Core {req.core_id}, Addr {req.addr}) <= {req.value}\")\n",
    "\n",
    "        self.cycle += 1\n",
    "\n",
    "    # Return the \"best\" request from the request queue\n",
    "    def _issue_best_request(self):\n",
    "\n",
    "        # Is the pending request queue empty?\n",
    "        if not self.pending:\n",
    "            print(f\"[Cycle {self.cycle}] No pending DDR requests to schedule.\")\n",
    "            return\n",
    "\n",
    "        # Sort the pending requests according to their \"score\"\n",
    "        self.pending.sort(key=lambda pair: self._score(pair[1], pair[0]))\n",
    "\n",
    "        for i, (arrival_time, req) in enumerate(self.pending):\n",
    "            bank = self._get_bank(req.addr)\n",
    "            row = self._get_row(req.addr)\n",
    "            last_time = self.last_address_time.get(req.addr, -1)\n",
    "\n",
    "            if last_time >= self.cycle:\n",
    "                continue\n",
    "\n",
    "            if self.bank_precharge_end[bank] > self.cycle:\n",
    "                continue  # Bank is busy\n",
    "\n",
    "            if self.bank_row_buffers[bank] == row:\n",
    "                delay = self.row_hit_latency\n",
    "                row_status = \"ROW HIT\"\n",
    "            else:\n",
    "                delay = self.precharge_time + self.row_miss_penalty + self.row_hit_latency\n",
    "                row_status = \"ROW MISS\"\n",
    "                self.bank_row_buffers[bank] = row\n",
    "                self.bank_precharge_end[bank] = self.cycle + self.precharge_time\n",
    "\n",
    "            completion_time = self.cycle + delay\n",
    "            req.completion_time = completion_time\n",
    "            self.last_address_time[req.addr] = completion_time\n",
    "            heapq.heappush(self.scheduled, (completion_time, req))\n",
    "            self.pending.pop(i)\n",
    "\n",
    "            print(f\"[Cycle {self.cycle}] ➜ Scheduling {req.req_type.upper()} for Addr {req.addr} (Core {req.core_id})\")\n",
    "            print(f\"                  ↳ Bank {bank}, Row {row} | {row_status} | Will complete at Cycle {completion_time}\")\n",
    "            break\n",
    "\n",
    "    # Compute a score for each request\n",
    "    def _score(self, req, arrival_time):\n",
    "        bank = self._get_bank(req.addr)\n",
    "        row = self._get_row(req.addr)\n",
    "        score = arrival_time\n",
    "\n",
    "        if self.bank_row_buffers[bank] == row:\n",
    "            score -= 100  # Favor row hits\n",
    "        elif self.bank_precharge_end[bank] > self.cycle:\n",
    "            score += 50  # Penalize busy banks\n",
    "\n",
    "        return score\n",
    "\n",
    "#---------------------------------------\n",
    "# Models one level in the cache hierarchy\n",
    "#----------------------------------------\n",
    "class CacheLevel:\n",
    "    def __init__(self, level_name, core_id, size, line_size, assoc, memory=None, write_back=True, write_allocate=True):\n",
    "        self.level = level_name\n",
    "        self.core_id = core_id\n",
    "        self.line_size = line_size\n",
    "        self.assoc = assoc\n",
    "        self.num_sets = (size // line_size) // assoc\n",
    "        self.sets = [[CacheLine() for _ in range(assoc)] for _ in range(self.num_sets)]\n",
    "        self.plru_trees = [PLRU(assoc) for _ in range(self.num_sets)]\n",
    "        self.memory = memory        # Could be DDR or next cache level\n",
    "        self.lower = None           # Lower level cache\n",
    "        self.write_back = write_back\n",
    "        self.write_allocate = write_allocate\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "\n",
    "    # Extract the set index from the address\n",
    "    #  addr = [ tag ][ idx ][ offset ]\n",
    "    def _index(self, addr):\n",
    "        return (addr // self.line_size) % self.num_sets\n",
    "\n",
    "    # Extract the tag from the address\n",
    "    #  addr = [ tag ][ idx ][ offset ]\n",
    "    def _tag(self, addr):\n",
    "        return addr // (self.line_size * self.num_sets)\n",
    "\n",
    "    # Handles cache read request\n",
    "    def read(self, addr, callback):\n",
    "        index = self._index(addr)\n",
    "        tag = self._tag(addr)\n",
    "        cache_set = self.sets[index]\n",
    "        plru = self.plru_trees[index]\n",
    "\n",
    "        # Seach the tag in the cache set\n",
    "        for i, line in enumerate(cache_set):\n",
    "            if line.valid and line.tag == tag:\n",
    "                # There is a hit.\n",
    "                print(f\"[{self.level} cache hit for {addr} on core {self.core_id}]\")\n",
    "                self.hits += 1\n",
    "                # Update the pLRU tree to point away from the MRU\n",
    "                plru.update_on_access(i)\n",
    "                callback(line.data)\n",
    "                return\n",
    "\n",
    "        print(f\"[{self.level} cache miss for {addr} on core {self.core_id}]\")\n",
    "        # On miss, choose victim line using PLRU and fetch from lower memory\n",
    "        self.misses += 1\n",
    "        victim_idx = plru.get_victim()\n",
    "        victim_line = cache_set[victim_idx]\n",
    "\n",
    "        # If the victime line is valid and dirty, we have to write the data to\n",
    "        # the next level of memory before loading the cache entry with the\n",
    "        # data.\n",
    "        def lower_cb(val):\n",
    "            # Write evicted data if dirty\n",
    "            if victim_line.valid and victim_line.dirty and self.write_back:\n",
    "                victim_addr = ((victim_line.tag * self.num_sets) + index) * self.line_size\n",
    "                if self.lower:\n",
    "                    self.lower.write(victim_addr, victim_line.data)\n",
    "                elif self.memory:\n",
    "                    self.memory.request(DDRRequest(self.core_id, self.memory.cycle, 'write', victim_addr, value=victim_line.data))\n",
    "            # Now that we have written the data to the next memory level, the\n",
    "            # cache entry is updated with the new data (val)\n",
    "            victim_line.valid = True\n",
    "            victim_line.tag = tag\n",
    "            victim_line.data = val\n",
    "            victim_line.dirty = False\n",
    "            plru.update_on_access(victim_idx)\n",
    "            callback(val)\n",
    "\n",
    "        # Forward the read request to the ower-level cache (if any)\n",
    "        if self.lower:\n",
    "            self.lower.read(addr, lower_cb)\n",
    "        # Or to DDR...\n",
    "        elif self.memory:\n",
    "            self.memory.request(DDRRequest(self.core_id, self.memory.cycle, 'read', addr, lower_cb))\n",
    "\n",
    "    # Handles cache write request\n",
    "    def write(self, addr, val):\n",
    "        index = self._index(addr)\n",
    "        tag = self._tag(addr)\n",
    "        cache_set = self.sets[index]\n",
    "        plru = self.plru_trees[index]\n",
    "        print(f\"[{self.level} cache write for {addr} on core {self.core_id}]\")\n",
    "\n",
    "        for i, line in enumerate(cache_set):\n",
    "            if line.valid and line.tag == tag:\n",
    "                # There is a cache hit\n",
    "                line.data = val\n",
    "                # If the cache is write-back, the data will be written to\n",
    "                # memory when evicted, so it is marked \"dirty\"\n",
    "                line.dirty = True if self.write_back else False\n",
    "                plru.update_on_access(i)\n",
    "                # If the cache is write-through, the write operation is\n",
    "                # propagated to the lower levels of the memory hierarchy\n",
    "                if not self.write_back:\n",
    "                    if self.lower:\n",
    "                        self.lower.write(addr, val)\n",
    "                    elif self.memory:\n",
    "                        self.memory.request(DDRRequest(self.core_id, self.memory.cycle, 'write', addr, value=val))\n",
    "                return\n",
    "\n",
    "        # There is a cache miss...\n",
    "        if self.write_allocate:\n",
    "            # Find the entry to be evicted.\n",
    "            victim_idx = plru.get_victim()\n",
    "            victim_line = cache_set[victim_idx]\n",
    "            # If we are in write-back mode and the cache line is dirty,\n",
    "            # it has to be written to the lower level of the memory hierarchy\n",
    "            # before being overwritten.\n",
    "            if victim_line.valid and victim_line.dirty and self.write_back:\n",
    "                victim_addr = ((victim_line.tag * self.num_sets) + index) * self.line_size\n",
    "                if self.lower:\n",
    "                    self.lower.write(victim_addr, victim_line.data)\n",
    "                elif self.memory:\n",
    "                    self.memory.request(DDRRequest(self.core_id, self.memory.cycle, 'write', victim_addr, value=victim_line.data))\n",
    "\n",
    "            # The entry is now valid\n",
    "            victim_line.valid = True\n",
    "            victim_line.tag = tag\n",
    "            victim_line.data = val\n",
    "            # It is dirty (only necessary if write back is active)\n",
    "            victim_line.dirty = self.write_back\n",
    "            plru.update_on_access(victim_idx)\n",
    "        else:\n",
    "            # If write allocate is false, the data is written to the next level\n",
    "            # of the memory hierachy.\n",
    "            if self.lower:\n",
    "                self.lower.write(addr, val)\n",
    "            elif self.memory:\n",
    "                self.memory.request(DDRRequest(self.core_id, self.memory.cycle, 'write', addr, value=val))\n",
    "\n",
    "    def stats(self):\n",
    "        total = self.hits + self.misses\n",
    "        return {\n",
    "            \"level\": self.level,\n",
    "            \"hits\": self.hits,\n",
    "            \"misses\": self.misses,\n",
    "            \"hit_rate\": self.hits / total if total else 0\n",
    "        }\n",
    "\n",
    "# Models full multi-level cache hierarchy for a core\n",
    "class MultiLevelCache:\n",
    "    def __init__(self, core_id, l1_conf, l2_conf, l3_conf, interconnect):\n",
    "        self.core_id = core_id\n",
    "        self.interconnect = interconnect\n",
    "        self.l1 = CacheLevel(\"L1\", core_id, memory=None, **l1_conf)\n",
    "        self.l2 = CacheLevel(\"L2\", core_id, memory=None, **l2_conf)\n",
    "        # Cache L3 is connected to the DDR memory\n",
    "        self.l3 = CacheLevel(\"L3\", core_id, memory=interconnect, **l3_conf)\n",
    "        # Cache L1 is connected to cache L2\n",
    "        self.l1.lower = self.l2\n",
    "        # Cache L2 is connected to cache L3\n",
    "        self.l2.lower = self.l3\n",
    "        # Cache L3 has no lower level cache.\n",
    "        self.l3.lower = None\n",
    "\n",
    "    def read(self, addr, callback):\n",
    "        self.l1.read(addr, callback)\n",
    "\n",
    "    def write(self, addr, val):\n",
    "        self.l1.write(addr, val)\n",
    "\n",
    "    def stats(self):\n",
    "        return {\n",
    "            \"core\": self.core_id,\n",
    "            \"L1\": self.l1.stats(),\n",
    "            \"L2\": self.l2.stats(),\n",
    "            \"L3\": self.l3.stats()\n",
    "        }\n",
    "\n",
    "# Simulation setup\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "ddr = DDRMemory()\n",
    "interconnect = Interconnect(ddr, delay=5, bandwidth=4)\n",
    "l1_conf = {'size': 32, 'line_size': 4, 'assoc': 2}\n",
    "l2_conf = {'size': 128, 'line_size': 4, 'assoc': 4}\n",
    "l3_conf = {'size': 512, 'line_size': 4, 'assoc': 8}\n",
    "\n",
    "core0 = MultiLevelCache(0, l1_conf, l2_conf, l3_conf, interconnect)\n",
    "core1 = MultiLevelCache(1, l1_conf, l2_conf, l3_conf, interconnect)\n",
    "\n",
    "# Run a small simulation loop with random accesses\n",
    "for cycle in range(100):\n",
    "    print(f\"\\n========== CYCLE {cycle} ==========\")\n",
    "    addr = random.randint(0, 20)\n",
    "    core = core0 if random.random() < 0.5 else core1\n",
    "    if random.random() < 0.5:\n",
    "        print(f\"write at {addr} for core {core.core_id}\")\n",
    "        core.write(addr, random.randint(0, 1000))\n",
    "    else:\n",
    "        print(f\"read at {addr} for core {core.core_id}\")\n",
    "        core.read(addr, lambda val: None)\n",
    "    interconnect.tick()\n",
    "    ddr.tick()\n",
    "\n",
    "# Report results\n",
    "print(core0.stats())\n",
    "print(core1.stats())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
